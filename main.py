# main.py
import asyncio
import io
import json
import os
import shutil
import subprocess
from typing import Optional
from pathlib import Path  # æ·»åŠ è¿™ä¸ªå¯¼å…¥
from vosk import Model, KaldiRecognizer
from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from fastapi.responses import HTMLResponse
from fastapi.staticfiles import StaticFiles
import uvicorn

from matcher import QuestionMatcher

app = FastAPI(title="é¢è¯•è¾…åŠ©å·¥å…· API", description="å®æ—¶è¯­éŸ³è¯†åˆ«å’Œé—®é¢˜åŒ¹é…æœåŠ¡")

# å…¨å±€å˜é‡
vosk_model: Optional[Model] = None # ç”¨äºåŠ è½½Voskæ¨¡å‹
matcher: Optional[QuestionMatcher] = None
interviewee_ws: Optional[WebSocket] = None

# --- ä¿®æ”¹ç‚¹ï¼šä½¿ç”¨æ›´å¯é çš„è·¯å¾„å®šä½æ–¹å¼ ---
def init_vosk_model():
    """åœ¨æœåŠ¡å¯åŠ¨æ—¶åŠ è½½Voskç¦»çº¿æ¨¡å‹"""
    global vosk_model
    
    # æ„å»ºç›¸å¯¹äºå½“å‰æ–‡ä»¶ä½ç½®çš„ç»å¯¹è·¯å¾„ï¼Œè¿™æ¯”ç›¸å¯¹è·¯å¾„æ›´å¯é 
    # Path(__file__) è·å–å½“å‰è„šæœ¬(main.py)çš„è·¯å¾„
    # .parent è·å–è¯¥è·¯å¾„çš„çˆ¶ç›®å½•
    # / "model" / "..." æ˜¯è·¨å¹³å°æ‹¼æ¥è·¯å¾„çš„æ–¹å¼
    model_path = Path(__file__).parent / "model" / "vosk-model-small-cn-0.22"
    
    print(f"æ­£åœ¨æ£€æŸ¥Voskæ¨¡å‹è·¯å¾„: {model_path}")
    
    if not model_path.exists():
        print(f"é”™è¯¯ï¼šVoskæ¨¡å‹æ–‡ä»¶å¤¹æœªæ‰¾åˆ°ï¼Œæ£€æŸ¥è·¯å¾„: '{model_path}'")
        print("è¯·ç¡®è®¤ 'model/vosk-model-small-cn-0.22' æ–‡ä»¶å¤¹å·²æ­£ç¡®æ”¾ç½®åœ¨é¡¹ç›®æ ¹ç›®å½•ã€‚")
        return False
    
    try:
        print("æ­£åœ¨åŠ è½½Voskæ¨¡å‹ï¼Œè¯·ç¨å€™...")
        vosk_model = Model(str(model_path)) # voskåº“éœ€è¦å­—ç¬¦ä¸²æ ¼å¼çš„è·¯å¾„
        print("âœ“ Voskæ¨¡å‹åŠ è½½æˆåŠŸ")
        return True
    except Exception as e:
        print(f"åŠ è½½Voskæ¨¡å‹å¤±è´¥: {e}")
        return False

# åˆå§‹åŒ–é—®é¢˜åŒ¹é…å™¨
def init_matcher():
    global matcher
    knowledge_base_path = 'knowledge_base.xlsx'
    
    if not os.path.exists(knowledge_base_path):
        print(f"è­¦å‘Šï¼šæœªæ‰¾åˆ°çŸ¥è¯†åº“æ–‡ä»¶ {knowledge_base_path}")
        print("è¯·åˆ›å»ºåŒ…å« 'question' å’Œ 'answer' åˆ—çš„Excelæ–‡ä»¶")
        return False
    
    try:
        matcher = QuestionMatcher(knowledge_base_path)
        return True
    except Exception as e:
        print(f"åˆå§‹åŒ–åŒ¹é…å™¨å¤±è´¥: {e}")
        return False

# --- ä¿®æ”¹åçš„éŸ³é¢‘è½¬æ¢å‡½æ•° ---
def convert_audio_to_wav(input_bytes: bytes) -> bytes:
    """ä½¿ç”¨FFmpegå°†ä»»æ„æ ¼å¼çš„éŸ³é¢‘å­—èŠ‚æµè½¬æ¢ä¸ºWAVæ ¼å¼çš„å­—èŠ‚æµ"""

    # --- è¯·åœ¨è¿™é‡Œå¡«å…¥æ‚¨ffmpeg.exeçš„å®Œæ•´è·¯å¾„ ---
    # ç¤ºä¾‹ (Windows): "C:\\ffmpeg\\bin\\ffmpeg.exe"  (æ³¨æ„æ˜¯åŒåæ–œæ )
    # ç¤ºä¾‹ (macOS/Linux): "/usr/local/bin/ffmpeg"
    FFMPEG_CMD = "ffmpeg"  # é»˜è®¤å€¼ï¼Œå¦‚æœä¸‹é¢çš„è·¯å¾„æ£€æŸ¥å¤±è´¥ï¼Œä¼šå°è¯•ä½¿ç”¨ç³»ç»ŸPATH

    # --- å°†ä½ çš„è·¯å¾„å¡«åœ¨è¿™é‡Œ ---
    # ä¾‹å¦‚ï¼š
    FFMPEG_CMD ="C:\\ffmpeg\\bin\\ffmpeg.exe"
    
    # æ£€æŸ¥æŒ‡å®šçš„è·¯å¾„æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨æˆ–æœªè®¾ç½®ï¼Œåˆ™å°è¯•ä½¿ç”¨ç³»ç»ŸPATH
    if not os.path.exists(FFMPEG_CMD):
        # å¦‚æœæŒ‡å®šè·¯å¾„ä¸å­˜åœ¨ï¼Œå°è¯•åœ¨ç³»ç»ŸPATHä¸­æŸ¥æ‰¾
        ffmpeg_in_path = shutil.which("ffmpeg")
        if ffmpeg_in_path:
            FFMPEG_CMD = ffmpeg_in_path
            print(f"ä½¿ç”¨ç³»ç»ŸPATHä¸­çš„ffmpeg: {FFMPEG_CMD}")
        else:
            print(f"é”™è¯¯ï¼šåœ¨æŒ‡å®šè·¯å¾„å’Œç³»ç»ŸPATHä¸­éƒ½æœªæ‰¾åˆ°ffmpegã€‚")
            print(f"è¯·æ£€æŸ¥ FFMPEG_CMD å˜é‡çš„è·¯å¾„æ˜¯å¦æ­£ç¡®: '{FFMPEG_CMD}'")
            raise RuntimeError("FFmpeg not found")
    
    command = [
        FFMPEG_CMD,
        '-i', 'pipe:0',
        '-ac', '1',
        '-ar', '16000',
        '-f', 'wav',
        'pipe:1'
    ]
    
    try:
        process = subprocess.Popen(
            command,
            stdin=subprocess.PIPE,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE
        )
        wav_bytes, err = process.communicate(input=input_bytes)
        
        if process.returncode != 0:
            print(f"FFmpegé”™è¯¯: {err.decode(errors='ignore')}")
            return None
        
        return wav_bytes
    except FileNotFoundError:
        print(f"é”™è¯¯: æ— æ³•æ‰§è¡Œå‘½ä»¤ '{FFMPEG_CMD}'ã€‚è¯·ç¡®ä¿è·¯å¾„æ­£ç¡®ä¸”æ–‡ä»¶æœ‰æ‰§è¡Œæƒé™ã€‚")
        return None
    except Exception as e:
        print(f"FFmpegè½¬æ¢æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
        return None


@app.on_event("startup")
async def startup_event():
    """æœåŠ¡å¯åŠ¨æ—¶åˆå§‹åŒ–"""
    print("=== é¢è¯•è¾…åŠ©å·¥å…·åç«¯æœåŠ¡å¯åŠ¨ ===")
    
    # é¦–å…ˆåˆå§‹åŒ–Voskæ¨¡å‹
    if init_vosk_model():
        print("âœ“ Voskè¯­éŸ³è¯†åˆ«æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ")
    else:
        print("âœ— Voskè¯­éŸ³è¯†åˆ«æ¨¡å‹åˆå§‹åŒ–å¤±è´¥")
        print("æ³¨æ„ï¼šè¯­éŸ³è¯†åˆ«åŠŸèƒ½å°†ä¸å¯ç”¨")
    
    # ç„¶ååˆå§‹åŒ–é—®é¢˜åŒ¹é…å™¨
    if init_matcher():
        print("âœ“ é—®é¢˜åŒ¹é…å™¨åˆå§‹åŒ–æˆåŠŸ")
        if matcher:
            stats = matcher.get_stats()
            print(f"âœ“ çŸ¥è¯†åº“åŠ è½½å®Œæˆï¼Œå…± {stats['total_questions']} ä¸ªé—®é¢˜")
    else:
        print("âœ— é—®é¢˜åŒ¹é…å™¨åˆå§‹åŒ–å¤±è´¥")
    
    print("æœåŠ¡å™¨å·²å¯åŠ¨ï¼Œç­‰å¾…è¿æ¥...")

@app.get("/", response_class=HTMLResponse)
async def get_interviewer_page():
    """æä¾›é¢è¯•å®˜æ‰‹æœºç«¯é¡µé¢"""
    html_content = """
<!DOCTYPE html>
<html>
<head>
    <title>é¢è¯•å®˜å½•éŸ³ç«¯</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta charset="utf-8">
    <style>
        body { 
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            text-align: center; 
            padding: 20px; 
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            min-height: 100vh;
            margin: 0;
        }
        .container {
            max-width: 400px;
            margin: 0 auto;
            background: rgba(255,255,255,0.1);
            padding: 30px;
            border-radius: 15px;
            backdrop-filter: blur(10px);
        }
        h1 { margin-bottom: 30px; font-size: 24px; }
        #status { 
            margin-bottom: 30px; 
            font-size: 16px; 
            padding: 15px;
            background: rgba(255,255,255,0.1);
            border-radius: 10px;
            min-height: 20px;
        }
        button { 
            font-size: 18px; 
            padding: 15px 30px; 
            cursor: pointer; 
            border: none;
            border-radius: 25px;
            margin: 10px;
            transition: all 0.3s ease;
            font-weight: bold;
        }
        button:hover { transform: translateY(-2px); }
        button:disabled { 
            opacity: 0.5; 
            cursor: not-allowed; 
            transform: none;
        }
        #startBtn { background: #4CAF50; color: white; }
        #stopBtn { background: #f44336; color: white; }
        .success { color: #4CAF50; }
        .error { color: #ff6b6b; }
        .warning { color: #ffa726; }
        .info { color: #29b6f6; }
    </style>
</head>
<body>
    <div class="container">
        <h1>ğŸ¤ é¢è¯•å®˜å½•éŸ³ç«¯</h1>
        <div id="status" class="info">æ­£åœ¨è¿æ¥æœåŠ¡å™¨...</div>
        <button id="startBtn" disabled>å¼€å§‹å½•éŸ³</button>
        <button id="stopBtn" disabled>åœæ­¢å½•éŸ³</button>
        <div style="margin-top: 20px; font-size: 12px; opacity: 0.8;">
            æ”¯æŒè¿ç»­å½•éŸ³ï¼Œè‡ªåŠ¨è¯­éŸ³è¯†åˆ«
        </div>
    </div>

    <script>
        const startBtn = document.getElementById('startBtn');
        const stopBtn = document.getElementById('stopBtn');
        const statusDiv = document.getElementById('status');
        let mediaRecorder;
        let ws;
        let audioChunks = [];
        let isRecording = false;

        function updateStatus(message, type = 'info') {
            statusDiv.textContent = message;
            statusDiv.className = type;
        }

        function connectWebSocket() {
            const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
            const wsUrl = `${protocol}//${window.location.host}/ws/interviewer`;
            
            ws = new WebSocket(wsUrl);

            ws.onopen = () => {
                updateStatus('å·²è¿æ¥æœåŠ¡å™¨ï¼Œå¯ä»¥å¼€å§‹å½•éŸ³', 'success');
                startBtn.disabled = false;
            };

            ws.onclose = () => {
                updateStatus('è¿æ¥æ–­å¼€ï¼Œè¯·åˆ·æ–°é¡µé¢é‡è¯•', 'error');
                startBtn.disabled = true;
                stopBtn.disabled = true;
                // å°è¯•é‡è¿
                setTimeout(connectWebSocket, 3000);
            };

            ws.onerror = (error) => {
                console.error('WebSocket Error:', error);
                updateStatus('è¿æ¥é”™è¯¯ï¼Œè¯·æ£€æŸ¥ç½‘ç»œ', 'error');
            };

            ws.onmessage = (event) => {
                const data = JSON.parse(event.data);
                if (data.type === 'recognition_result') {
                    updateStatus(`è¯†åˆ«ç»“æœ: ${data.text}`, 'info');
                } else if (data.type === 'match_result') {
                    updateStatus(`åŒ¹é…æˆåŠŸ: ${data.question}`, 'success');
                }
            };
        }

        async function startRecording() {
            if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
                alert('æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒå½•éŸ³åŠŸèƒ½');
                return;
            }

            try {
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        sampleRate: 16000,
                        channelCount: 1,
                        echoCancellation: true,
                        noiseSuppression: true
                    }
                });

                audioChunks = [];
                mediaRecorder = new MediaRecorder(stream);

                mediaRecorder.ondataavailable = event => {
                    if (event.data.size > 0) {
                        audioChunks.push(event.data);
                    }
                };

                mediaRecorder.onstop = () => {
                    const audioBlob = new Blob(audioChunks);
                    if (ws && ws.readyState === WebSocket.OPEN) {
                        ws.send(audioBlob);
                        updateStatus('éŸ³é¢‘å·²å‘é€ï¼Œæ­£åœ¨è¯†åˆ«...', 'warning');
                    }
                };

                // æ¯3ç§’é’Ÿè‡ªåŠ¨åœæ­¢å¹¶å‘é€ä¸€æ¬¡
                mediaRecorder.start();
                isRecording = true;
                
                startBtn.disabled = true;
                stopBtn.disabled = false;
                updateStatus('æ­£åœ¨å½•éŸ³ä¸­...', 'warning');

                // è®¾ç½®å®šæ—¶å‘é€
                setTimeout(() => {
                    if (isRecording && mediaRecorder && mediaRecorder.state === 'recording') {
                        mediaRecorder.stop();
                        setTimeout(() => {
                            if (isRecording) {
                                startRecording(); // é‡æ–°å¼€å§‹å½•éŸ³
                            }
                        }, 500);
                    }
                }, 3000);

            } catch (error) {
                console.error('å½•éŸ³å¤±è´¥:', error);
                updateStatus('å½•éŸ³å¤±è´¥ï¼Œè¯·æ£€æŸ¥éº¦å…‹é£æƒé™', 'error');
            }
        }

        function stopRecording() {
            isRecording = false;
            if (mediaRecorder && mediaRecorder.state === 'recording') {
                mediaRecorder.stop();
            }
            startBtn.disabled = false;
            stopBtn.disabled = true;
            updateStatus('å·²åœæ­¢å½•éŸ³', 'info');
        }

        startBtn.onclick = startRecording;
        stopBtn.onclick = stopRecording;

        // é¡µé¢åŠ è½½æ—¶è¿æ¥WebSocket
        window.onload = connectWebSocket;
    </script>
</body>
</html>
    """
    return HTMLResponse(content=html_content)

@app.websocket("/ws/interviewee")
async def interviewee_websocket_endpoint(websocket: WebSocket):
    """é¢è¯•è€…å®¢æˆ·ç«¯è¿æ¥ç‚¹"""
    global interviewee_ws
    await websocket.accept()
    interviewee_ws = websocket
    print("âœ“ é¢è¯•è€…å®¢æˆ·ç«¯å·²è¿æ¥")
    
    try:
        while True:
            # ä¿æŒè¿æ¥ï¼Œå¯ä»¥æ¥æ”¶å¿ƒè·³æˆ–å‘½ä»¤
            data = await websocket.receive_text()
            if data == "ping":
                await websocket.send_text("pong")
    except WebSocketDisconnect:
        interviewee_ws = None
        print("âœ— é¢è¯•è€…å®¢æˆ·ç«¯å·²æ–­å¼€")

@app.websocket("/ws/interviewer")
async def interviewer_websocket_endpoint(websocket: WebSocket):
    """é¢è¯•å®˜æ‰‹æœºè¿æ¥ç‚¹"""
    await websocket.accept()
    print("âœ“ é¢è¯•å®˜æ‰‹æœºç«¯å·²è¿æ¥")
    
    try:
        while True:
            # æ¥æ”¶éŸ³é¢‘æ•°æ®
            audio_data = await websocket.receive_bytes()
            print(f"æ”¶åˆ°éŸ³é¢‘æ•°æ®ï¼Œå¤§å°: {len(audio_data)} å­—èŠ‚")
            
            # åœ¨å¤„ç†å‰å…ˆè¿›è¡Œæ ¼å¼è½¬æ¢
            wav_audio_data = convert_audio_to_wav(audio_data)
            
            if wav_audio_data:
                # ä½¿ç”¨è½¬æ¢åçš„æ•°æ®è¿›è¡Œå¤„ç†
                await process_audio(websocket, wav_audio_data)
            else:
                print("âœ— éŸ³é¢‘è½¬æ¢å¤±è´¥ï¼Œè·³è¿‡å¤„ç†")
            
    except WebSocketDisconnect:
        print("âœ— é¢è¯•å®˜æ‰‹æœºç«¯å·²æ–­å¼€")
    except Exception as e:
        print(f"å¤„ç†éŸ³é¢‘æ—¶å‡ºé”™: {e}")

# --- ä¿®æ”¹ç‚¹ï¼šæ ¸å¿ƒå¤„ç†é€»è¾‘å®Œå…¨é‡å†™ä»¥ä½¿ç”¨Vosk ---
async def process_audio(websocket: WebSocket, audio_data: bytes):
    """ä½¿ç”¨Voskå¤„ç†éŸ³é¢‘è¯†åˆ«å’ŒåŒ¹é…"""
    # æ£€æŸ¥Voskæ¨¡å‹æ˜¯å¦å·²åŠ è½½
    if not vosk_model:
        print("âœ— Voskæ¨¡å‹æœªåŠ è½½ï¼Œæ— æ³•è¿›è¡Œè¯†åˆ«")
        await websocket.send_text(json.dumps({
            'type': 'error', 
            'message': 'Voskè¯­éŸ³è¯†åˆ«æ¨¡å‹æœªåŠ è½½'
        }))
        return

    try:
        # åˆ›å»ºä¸€ä¸ªè¯†åˆ«å™¨å®ä¾‹
        # ç¬¬äºŒä¸ªå‚æ•°æ˜¯é‡‡æ ·ç‡ï¼Œå¿…é¡»ä¸ffmpegè½¬æ¢æ—¶è®¾ç½®çš„16000ä¸€è‡´
        rec = KaldiRecognizer(vosk_model, 16000)
        
        # å°†æ•´ä¸ªWAVæ–‡ä»¶çš„å­—èŠ‚å–‚ç»™è¯†åˆ«å™¨
        rec.AcceptWaveform(audio_data)
        
        # è·å–æœ€ç»ˆè¯†åˆ«ç»“æœ
        result = json.loads(rec.FinalResult())
        text = result.get('text', '').replace(' ', '') # è·å–æ–‡æœ¬å¹¶ç§»é™¤ç©ºæ ¼
        
        if text:
            print(f"âœ“ ç¦»çº¿è¯†åˆ«ç»“æœ: {text}")
            
            # å‘é€è¯†åˆ«ç»“æœç»™é¢è¯•å®˜
            await websocket.send_text(json.dumps({
                'type': 'recognition_result',
                'text': text
            }))

            # åŒ¹é…ç­”æ¡ˆ (è¿™éƒ¨åˆ†é€»è¾‘ä¸å˜)
            if matcher:
                match_result = matcher.match(text)
                
                if match_result:
                    answer = match_result['answer']
                    question = match_result['question']
                    similarity = match_result['similarity']
                    
                    print(f"âœ“ æ‰¾åˆ°åŒ¹é…ç­”æ¡ˆï¼Œç›¸ä¼¼åº¦: {similarity:.3f}")
                    
                    await websocket.send_text(json.dumps({
                        'type': 'match_result', 'question': question, 'similarity': similarity
                    }))
                    
                    if interviewee_ws:
                        formatted_answer = f"é—®é¢˜: {question}\n\nç­”æ¡ˆ: {answer}\n\n(ç›¸ä¼¼åº¦: {similarity:.2f})"
                        await interviewee_ws.send_text(formatted_answer)
                        print(f"âœ“ å·²å‘é€ç­”æ¡ˆç»™é¢è¯•è€…: {answer[:30]}...")
                else:
                    print("âœ— æœªæ‰¾åˆ°åŒ¹é…çš„ç­”æ¡ˆ")
                    if interviewee_ws:
                        await interviewee_ws.send_text(f"æœªæ‰¾åˆ°åŒ¹é…ç­”æ¡ˆ: {text}")
            else:
                print("âœ— é—®é¢˜åŒ¹é…å™¨æœªåˆå§‹åŒ–")

        else:
            print("âœ— ç¦»çº¿è¯†åˆ«æœªèƒ½è§£æå‡ºæ–‡æœ¬")
            await websocket.send_text(json.dumps({
                'type': 'error', 'message': 'æ— æ³•ç†è§£éŸ³é¢‘å†…å®¹'
            }))

    except Exception as e:
        print(f"âœ— ç¦»çº¿è¯†åˆ«å¤„ç†æ—¶å‡ºé”™: {e}")
        await websocket.send_text(json.dumps({
            'type': 'error', 'message': f'å¤„ç†éŸ³é¢‘æ—¶å‡ºé”™: {e}'
        }))

@app.get("/status")
async def get_status():
    """è·å–æœåŠ¡çŠ¶æ€"""
    return {
        'status': 'running',
        'vosk_model_loaded': vosk_model is not None,
        'matcher_loaded': matcher is not None,
        'interviewee_connected': interviewee_ws is not None,
        'knowledge_base_stats': matcher.get_stats() if matcher else None
    }

if __name__ == "__main__":
    print("å¯åŠ¨é¢è¯•è¾…åŠ©å·¥å…·åç«¯æœåŠ¡...")
    uvicorn.run(app, host="0.0.0.0", port=8000)