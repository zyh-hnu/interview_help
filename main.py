# main.py
import asyncio
import io
import json
import os
import shutil
import subprocess
from typing import Optional
from pathlib import Path  # æ·»åŠ è¿™ä¸ªå¯¼å…¥
from contextlib import asynccontextmanager  # æ·»åŠ è¿™ä¸ªå¯¼å…¥
from vosk import Model, KaldiRecognizer,SetLogLevel
from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from fastapi.responses import HTMLResponse
from fastapi.staticfiles import StaticFiles
import uvicorn
import asyncio

from matcher import SemanticQuestionMatcher

import jieba.analyse
import jieba.posseg as pseg

#å¥å­æ¸…æ´—åŠŸèƒ½
class RefinedProcessor:
    def __init__(self):
        self.stop_words=self._load_stop_words()
        jieba.lcut("é¢„çƒ­",cut_all=False)
        print("âœ“ æ–‡æœ¬å¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ")

    def _load_stop_words(self):
        # å®é™…é¡¹ç›®ä¸­å¯ä»¥ä»æ–‡ä»¶åŠ è½½æ›´ä¸°å¯Œçš„åœç”¨è¯è¡¨
        return {
            'çš„', 'äº†', 'å‘¢', 'å•Š', 'å“¦', 'å—¯', 'è¿™ä¸ª', 'é‚£ä¸ª', 'æˆ‘æƒ³','é—®ä¸€ä¸‹',
            'è¯·é—®', 'å°±æ˜¯', 'ç„¶å', 'å…¶å®', 'å¯¹äº', 'å§', 'å‘€', 'å“ˆ', 'ä¹ˆ','å…¶å®','ä¹‹å','é‚£ä¹ˆ'
        }

    def clean_and_rebuild(self, text: str) -> str:
        """
        å¯¹æ–‡æœ¬è¿›è¡Œåˆ†è¯ï¼Œç§»é™¤åœç”¨è¯ï¼Œç„¶åé‡ç»„æˆä¸€ä¸ªå¹²å‡€çš„å¥å­ã€‚
        Args:
            text: ASRè¯†åˆ«å‡ºçš„åŸå§‹æ–‡æœ¬
            
        Returns:
            ç”±å…³é”®è¯ç»„æˆçš„æ›´å¹²å‡€çš„æ–‡æœ¬å­—ç¬¦ä¸²
        """
        if not text:
            return ""
        
        
        # 1. ä½¿ç”¨jiebaè¿›è¡Œç²¾ç¡®æ¨¡å¼åˆ†è¯
        words=jieba.lcut(text.strip(),cut_all=False)

        # 2. è¿‡æ»¤æ‰åœç”¨è¯ å’Œ å•ä¸ªå­—ç¬¦çš„è¯ (å¯ä»¥è¿‡æ»¤æ‰å¾ˆå¤šæ— æ„ä¹‰çš„è¯)
        filtered_words = [word for word in words if word not in self.stop_words and len(word.strip()) > 1]

        # å¦‚æœè¿‡æ»¤åä»€ä¹ˆéƒ½ä¸å‰©ï¼Œå¯ä»¥å°è¯•è¿”å›åŸå§‹æ–‡æœ¬ï¼Œæˆ–è€…ä¸€ä¸ªç¨å¾®ä¸é‚£ä¹ˆä¸¥æ ¼çš„è¿‡æ»¤ç»“æœ
        if not filtered_words:
            # ç­–ç•¥ï¼šå¦‚æœä¸¥æ ¼è¿‡æ»¤åä¸ºç©ºï¼Œæ”¾å®½æ¡ä»¶ï¼Œåªè¿‡æ»¤åœç”¨è¯ï¼Œä¿ç•™å•å­—ç¬¦
            filtered_words = [word for word in words if word not in self.stop_words]
        
        # 3. å°†è¿‡æ»¤åçš„è¯é‡æ–°æ‹¼æ¥æˆå¥å­
        cleaned_text = "".join(filtered_words)  # ä½¿ç”¨""æ‹¼æ¥ï¼Œæ›´åƒä¸€ä¸ªå¥å­
        
        print(f"åŸå§‹æ–‡æœ¬: '{text}' -> æ¸…ç†å: '{cleaned_text}'")
        
        return cleaned_text


# --- ä¿®æ”¹ç‚¹ï¼šä½¿ç”¨æ–°çš„lifespanäº‹ä»¶å¤„ç†å™¨ ---
@asynccontextmanager
async def lifespan(app: FastAPI):
    global processor
    processor=RefinedProcessor()
    
    # åº”ç”¨å¯åŠ¨æ—¶æ‰§è¡Œ
    print("=== é¢è¯•è¾…åŠ©å·¥å…·åç«¯æœåŠ¡å¯åŠ¨ ===")

    # é¦–å…ˆåˆå§‹åŒ–Voskæ¨¡å‹
    if init_vosk_model():
        print("âœ“ Voskè¯­éŸ³è¯†åˆ«æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ")
    else:
        print("âœ— Voskè¯­éŸ³è¯†åˆ«æ¨¡å‹åˆå§‹åŒ–å¤±è´¥")
        print("æ³¨æ„ï¼šè¯­éŸ³è¯†åˆ«åŠŸèƒ½å°†ä¸å¯ç”¨")
    
    # ç„¶ååˆå§‹åŒ–é—®é¢˜åŒ¹é…å™¨
    if init_matcher():
        print("âœ“ é—®é¢˜åŒ¹é…å™¨åˆå§‹åŒ–æˆåŠŸ")
        if matcher:
            stats = matcher.get_stats()
            print(f"âœ“ çŸ¥è¯†åº“åŠ è½½å®Œæˆï¼Œå…± {stats['total_questions']} ä¸ªé—®é¢˜")
    else:
        print("âœ— é—®é¢˜åŒ¹é…å™¨åˆå§‹åŒ–å¤±è´¥")
    
    print("æœåŠ¡å™¨å·²å¯åŠ¨ï¼Œç­‰å¾…è¿æ¥...")
    
    yield  # æœåŠ¡åœ¨æ­¤å¤„è¿è¡Œ
    
    # åº”ç”¨å…³é—­æ—¶æ‰§è¡Œçš„ä»£ç å¯ä»¥æ”¾åœ¨è¿™é‡Œ
    print("=== é¢è¯•è¾…åŠ©å·¥å…·åç«¯æœåŠ¡å…³é—­ ===")


app = FastAPI(
    title="é¢è¯•è¾…åŠ©å·¥å…· API", 
    description="å®æ—¶è¯­éŸ³è¯†åˆ«å’Œé—®é¢˜åŒ¹é…æœåŠ¡",
    lifespan=lifespan  # å°†lifespanç®¡ç†å™¨æ³¨å†Œåˆ°åº”ç”¨
)
# å…¨å±€å˜é‡
vosk_model: Optional[Model] = None # ç”¨äºåŠ è½½Voskæ¨¡å‹
matcher: Optional[SemanticQuestionMatcher] = None
interviewee_ws: Optional[WebSocket] = None
processor: Optional[RefinedProcessor]=None 

def init_vosk_model():
    """åœ¨æœåŠ¡å¯åŠ¨æ—¶åŠ è½½Voskç¦»çº¿æ¨¡å‹"""
    global vosk_model
    
    # æ„å»ºç›¸å¯¹äºå½“å‰æ–‡ä»¶ä½ç½®çš„ç»å¯¹è·¯å¾„ï¼Œè¿™æ¯”ç›¸å¯¹è·¯å¾„æ›´å¯é 
    # Path(__file__) è·å–å½“å‰è„šæœ¬(main.py)çš„è·¯å¾„
    # .parent è·å–è¯¥è·¯å¾„çš„çˆ¶ç›®å½•
    # / "model" / "..." æ˜¯è·¨å¹³å°æ‹¼æ¥è·¯å¾„çš„æ–¹å¼
    model_path = Path(__file__).parent / "model" / "vosk-model-cn-0.22"
    
    print(f"æ­£åœ¨æ£€æŸ¥Voskæ¨¡å‹è·¯å¾„: {model_path}")
    
    if not model_path.exists():
        print(f"é”™è¯¯ï¼šVoskæ¨¡å‹æ–‡ä»¶å¤¹æœªæ‰¾åˆ°ï¼Œæ£€æŸ¥è·¯å¾„: '{model_path}'")
        print("è¯·ç¡®è®¤ 'model/vosk-model-cn-0.22' æ–‡ä»¶å¤¹å·²æ­£ç¡®æ”¾ç½®åœ¨é¡¹ç›®æ ¹ç›®å½•ã€‚")
        return False
    
    try:
        SetLogLevel(-1)
        print("æ­£åœ¨åŠ è½½Voskæ¨¡å‹ï¼Œè¯·ç¨å€™...")
        vosk_model = Model(str(model_path)) # voskåº“éœ€è¦å­—ç¬¦ä¸²æ ¼å¼çš„è·¯å¾„
        print("âœ“ Voskæ¨¡å‹åŠ è½½æˆåŠŸ")
        return True
    except Exception as e:
        print(f"åŠ è½½Voskæ¨¡å‹å¤±è´¥: {e}")
        return False

# åˆå§‹åŒ–é—®é¢˜åŒ¹é…å™¨
def init_matcher():
    global matcher
    knowledge_base_path = 'knowledge_base.xlsx'
    
    if not os.path.exists(knowledge_base_path):
        print(f"è­¦å‘Šï¼šæœªæ‰¾åˆ°çŸ¥è¯†åº“æ–‡ä»¶ {knowledge_base_path}")
        print("è¯·åˆ›å»ºåŒ…å« 'question' å’Œ 'answer' åˆ—çš„Excelæ–‡ä»¶")
        return False
    
    try:
        matcher= SemanticQuestionMatcher(knowledge_base_path)
        return True
    except Exception as e:
        print(f"åˆå§‹åŒ–åŒ¹é…å™¨å¤±è´¥: {e}")
        return False

# --- ä¿®æ”¹åçš„éŸ³é¢‘è½¬æ¢å‡½æ•° ---
def convert_audio_to_wav(input_bytes: bytes) -> bytes:
    """ä½¿ç”¨FFmpegå°†ä»»æ„æ ¼å¼çš„éŸ³é¢‘å­—èŠ‚æµè½¬æ¢ä¸ºWAVæ ¼å¼çš„å­—èŠ‚æµ"""

    # --- è¯·åœ¨è¿™é‡Œå¡«å…¥æ‚¨ffmpeg.exeçš„å®Œæ•´è·¯å¾„ ---
    # ç¤ºä¾‹ (Windows): "C:\\ffmpeg\\bin\\ffmpeg.exe"  (æ³¨æ„æ˜¯åŒåæ–œæ )
    # ç¤ºä¾‹ (macOS/Linux): "/usr/local/bin/ffmpeg"
    FFMPEG_CMD = "ffmpeg"  # é»˜è®¤å€¼ï¼Œå¦‚æœä¸‹é¢çš„è·¯å¾„æ£€æŸ¥å¤±è´¥ï¼Œä¼šå°è¯•ä½¿ç”¨ç³»ç»ŸPATH

    # --- å°†ä½ çš„è·¯å¾„å¡«åœ¨è¿™é‡Œ ---
    # ä¾‹å¦‚ï¼š
    FFMPEG_CMD ="C:\\ffmpeg\\bin\\ffmpeg.exe"
    
    # æ£€æŸ¥æŒ‡å®šçš„è·¯å¾„æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨æˆ–æœªè®¾ç½®ï¼Œåˆ™å°è¯•ä½¿ç”¨ç³»ç»ŸPATH
    if not os.path.exists(FFMPEG_CMD):
        # å¦‚æœæŒ‡å®šè·¯å¾„ä¸å­˜åœ¨ï¼Œå°è¯•åœ¨ç³»ç»ŸPATHä¸­æŸ¥æ‰¾
        ffmpeg_in_path = shutil.which("ffmpeg")
        if ffmpeg_in_path:
            FFMPEG_CMD = ffmpeg_in_path
            print(f"ä½¿ç”¨ç³»ç»ŸPATHä¸­çš„ffmpeg: {FFMPEG_CMD}")
        else:
            print(f"é”™è¯¯ï¼šåœ¨æŒ‡å®šè·¯å¾„å’Œç³»ç»ŸPATHä¸­éƒ½æœªæ‰¾åˆ°ffmpegã€‚")
            print(f"è¯·æ£€æŸ¥ FFMPEG_CMD å˜é‡çš„è·¯å¾„æ˜¯å¦æ­£ç¡®: '{FFMPEG_CMD}'")
            raise RuntimeError("FFmpeg not found")
    
    command = [
        FFMPEG_CMD,
        '-i', 'pipe:0',
        '-ac', '1',
        '-ar', '16000',
        '-f', 'wav',
        'pipe:1'
    ]
    
    try:
        process = subprocess.Popen(
            command,
            stdin=subprocess.PIPE,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE
        )
        wav_bytes, err = process.communicate(input=input_bytes)
        
        if process.returncode != 0:
            print(f"FFmpegé”™è¯¯: {err.decode(errors='ignore')}")
            return None
        
        return wav_bytes
    except FileNotFoundError:
        print(f"é”™è¯¯: æ— æ³•æ‰§è¡Œå‘½ä»¤ '{FFMPEG_CMD}'ã€‚è¯·ç¡®ä¿è·¯å¾„æ­£ç¡®ä¸”æ–‡ä»¶æœ‰æ‰§è¡Œæƒé™ã€‚")
        return None
    except Exception as e:
        print(f"FFmpegè½¬æ¢æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
        return None

@app.get("/", response_class=HTMLResponse)
async def get_interviewer_page():
    """æä¾›é¢è¯•å®˜æ‰‹æœºç«¯é¡µé¢ - é›†æˆVADåŠŸèƒ½"""
    html_content = """
<!DOCTYPE html>
<html>
<head>
    <title>é¢è¯•å®˜å½•éŸ³ç«¯ - æ™ºèƒ½VAD</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta charset="utf-8">
    <style>
        body { 
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            text-align: center; 
            padding: 20px; 
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            min-height: 100vh;
            margin: 0;
        }
        .container {
            max-width: 450px;
            margin: 0 auto;
            background: rgba(255,255,255,0.1);
            padding: 30px;
            border-radius: 15px;
            backdrop-filter: blur(10px);
        }
        h1 { margin-bottom: 20px; font-size: 24px; }
        .subtitle { margin-bottom: 30px; font-size: 14px; opacity: 0.8; }
        #status { 
            margin-bottom: 20px; 
            font-size: 16px; 
            padding: 15px;
            background: rgba(255,255,255,0.1);
            border-radius: 10px;
            min-height: 20px;
        }
        #vadStatus {
            margin-bottom: 20px;
            font-size: 14px;
            padding: 10px;
            background: rgba(255,255,255,0.05);
            border-radius: 8px;
            border: 1px solid rgba(255,255,255,0.2);
        }
        .audio-indicator {
            display: inline-block;
            width: 12px;
            height: 12px;
            border-radius: 50%;
            margin-right: 8px;
            background: #666;
            transition: background 0.3s ease;
        }
        .audio-indicator.speaking {
            background: #4CAF50;
            animation: pulse 1s infinite;
        }
        .audio-indicator.silence {
            background: #ff9800;
        }
        @keyframes pulse {
            0% { transform: scale(1); opacity: 1; }
            50% { transform: scale(1.2); opacity: 0.7; }
            100% { transform: scale(1); opacity: 1; }
        }
        button { 
            font-size: 18px; 
            padding: 15px 30px; 
            cursor: pointer; 
            border: none;
            border-radius: 25px;
            margin: 10px;
            transition: all 0.3s ease;
            font-weight: bold;
            min-width: 120px;
        }
        button:hover { transform: translateY(-2px); }
        button:disabled { 
            opacity: 0.5; 
            cursor: not-allowed; 
            transform: none;
        }
        #startBtn { background: #4CAF50; color: white; }
        #stopBtn { background: #f44336; color: white; }
        .success { color: #4CAF50; }
        .error { color: #ff6b6b; }
        .warning { color: #ffa726; }
        .info { color: #29b6f6; }
        .stats {
            margin-top: 20px;
            font-size: 12px;
            opacity: 0.7;
            background: rgba(255,255,255,0.05);
            padding: 10px;
            border-radius: 8px;
        }
        .loading {
            display: inline-block;
            width: 20px;
            height: 20px;
            border: 2px solid rgba(255,255,255,0.3);
            border-radius: 50%;
            border-top-color: white;
            animation: spin 1s ease-in-out infinite;
            margin-right: 10px;
        }
        @keyframes spin {
            to { transform: rotate(360deg); }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>ğŸ¤ é¢è¯•å®˜å½•éŸ³ç«¯</h1>
        <div class="subtitle">åŸºäºVADçš„æ™ºèƒ½è¯­éŸ³æ£€æµ‹</div>
        
        <div id="status" class="info">
            <span class="loading"></span>æ­£åœ¨åŠ è½½VADæ¨¡å‹...
        </div>
        
        <div id="vadStatus">
            <span class="audio-indicator" id="audioIndicator"></span>
            <span id="vadText">ç­‰å¾…å¼€å§‹...</span>
        </div>
        
        <button id="startBtn" disabled>å¼€å§‹æ™ºèƒ½å½•éŸ³</button>
        <button id="stopBtn" disabled>åœæ­¢å½•éŸ³</button>
        
        <div class="stats">
            <div>å‘é€è¯­éŸ³ç‰‡æ®µ: <span id="sentCount">0</span></div>
            <div>è¯†åˆ«æˆåŠŸ: <span id="recognizedCount">0</span></div>
            <div>åŒ¹é…æˆåŠŸ: <span id="matchedCount">0</span></div>
        </div>
    </div>

    <!-- æŒ‰ç…§æœ€æ–°APIåŠ è½½VADåº“ -->
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web@1.14.0/dist/ort.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@ricky0123/vad-web@0.0.22/dist/bundle.min.js"></script>
    
    <script>
        // DOMå…ƒç´ 
        const startBtn = document.getElementById('startBtn');
        const stopBtn = document.getElementById('stopBtn');
        const statusDiv = document.getElementById('status');
        const vadText = document.getElementById('vadText');
        const audioIndicator = document.getElementById('audioIndicator');
        const sentCount = document.getElementById('sentCount');
        const recognizedCount = document.getElementById('recognizedCount');
        const matchedCount = document.getElementById('matchedCount');

        // å…¨å±€å˜é‡
        let myvad = null;
        let ws = null;
        let isRecording = false;
        let stats = { sent: 0, recognized: 0, matched: 0 };

        function updateStatus(message, type = 'info') {
            statusDiv.innerHTML = message;
            statusDiv.className = type;
        }

        function updateVadStatus(text, isSpeaking = false) {
            vadText.textContent = text;
            audioIndicator.className = isSpeaking ? 'audio-indicator speaking' : 'audio-indicator silence';
        }

        function updateStats() {
            sentCount.textContent = stats.sent;
            recognizedCount.textContent = stats.recognized;
            matchedCount.textContent = stats.matched;
        }

        // å°†Float32Arrayè½¬æ¢ä¸ºWAVæ ¼å¼
        function encodeWAV(samples, sampleRate = 16000) {
            const buffer = new ArrayBuffer(44 + samples.length * 2);
            const view = new DataView(buffer);
            
            // WAVå¤´éƒ¨
            const writeString = (offset, string) => {
                for (let i = 0; i < string.length; i++) {
                    view.setUint8(offset + i, string.charCodeAt(i));
                }
            };
            
            writeString(0, 'RIFF');
            view.setUint32(4, 36 + samples.length * 2, true);
            writeString(8, 'WAVE');
            writeString(12, 'fmt ');
            view.setUint32(16, 16, true);
            view.setUint16(20, 1, true);
            view.setUint16(22, 1, true);
            view.setUint32(24, sampleRate, true);
            view.setUint32(28, sampleRate * 2, true);
            view.setUint16(32, 2, true);
            view.setUint16(34, 16, true);
            writeString(36, 'data');
            view.setUint32(40, samples.length * 2, true);
            
            // å†™å…¥éŸ³é¢‘æ•°æ®
            const offset = 44;
            for (let i = 0; i < samples.length; i++) {
                const sample = Math.max(-1, Math.min(1, samples[i]));
                view.setInt16(offset + i * 2, sample * 0x7FFF, true);
            }
            
            return buffer;
        }

        // åˆå§‹åŒ–VAD
        async function initializeVAD() {
            try {
                updateStatus('<span class="loading"></span>æ­£åœ¨åˆå§‹åŒ–VADæ¨¡å‹...', 'warning');
                
                // ä½¿ç”¨æœ€æ–°çš„APIåˆ›å»ºVADå®ä¾‹
                myvad = await vad.MicVAD.new({
                    onSpeechStart: () => {
                        console.log("æ£€æµ‹åˆ°è¯­éŸ³å¼€å§‹");
                        updateVadStatus('æ­£åœ¨è¯´è¯...', true);
                    },
                    
                    onSpeechEnd: (audio) => {
                        console.log(`è¯­éŸ³ç»“æŸï¼ŒéŸ³é¢‘é•¿åº¦: ${audio.length} é‡‡æ ·ç‚¹`);
                        updateVadStatus('å¤„ç†ä¸­...', false);
                        
                        try {
                            // è½¬æ¢ä¸ºWAVæ ¼å¼
                            const wavBuffer = encodeWAV(audio);
                            const audioBlob = new Blob([wavBuffer], { type: 'audio/wav' });
                            
                            // å‘é€ç»™åç«¯
                            if (ws && ws.readyState === WebSocket.OPEN && audioBlob.size > 1000) {
                                ws.send(audioBlob);
                                stats.sent++;
                                updateStats();
                                updateStatus(`å‘é€éŸ³é¢‘ç‰‡æ®µ ${stats.sent}`, 'info');
                            }
                        } catch (error) {
                            console.error('éŸ³é¢‘å¤„ç†å¤±è´¥:', error);
                            updateStatus('éŸ³é¢‘å¤„ç†å¤±è´¥', 'error');
                        }
                        
                        // é‡ç½®çŠ¶æ€
                        setTimeout(() => {
                            if (isRecording) {
                                updateVadStatus('ç­‰å¾…è¯­éŸ³...', false);
                            }
                        }, 1000);
                    },
                    
                    onVADMisfire: () => {
                        console.log("VADè¯¯è§¦å‘");
                        updateVadStatus('ç­‰å¾…è¯­éŸ³...', false);
                    }
                });
                
                updateStatus('VADæ¨¡å‹åŠ è½½æˆåŠŸ', 'success');
                return true;
                
            } catch (error) {
                console.error('VADåˆå§‹åŒ–å¤±è´¥:', error);
                updateStatus(`VADåˆå§‹åŒ–å¤±è´¥: ${error.message}`, 'error');
                return false;
            }
        }

        // å¼€å§‹å½•éŸ³
        async function startRecording() {
            if (isRecording) return;
            
            startBtn.disabled = true;
            
            try {
                // å¦‚æœVADæœªåˆå§‹åŒ–ï¼Œå…ˆåˆå§‹åŒ–
                if (!myvad) {
                    const success = await initializeVAD();
                    if (!success) {
                        startBtn.disabled = false;
                        return;
                    }
                }
                
                // å¯åŠ¨VAD
                await myvad.start();
                
                isRecording = true;
                stopBtn.disabled = false;
                updateStatus('æ™ºèƒ½å½•éŸ³å·²å¯åŠ¨', 'success');
                updateVadStatus('ç­‰å¾…è¯­éŸ³...', false);
                
            } catch (error) {
                console.error('å¯åŠ¨å½•éŸ³å¤±è´¥:', error);
                updateStatus(`å¯åŠ¨å½•éŸ³å¤±è´¥: ${error.message}`, 'error');
                startBtn.disabled = false;
            }
        }

        // åœæ­¢å½•éŸ³
        async function stopRecording() {
            if (!isRecording || !myvad) return;
            
            try {
                await myvad.pause();
                isRecording = false;
                
                startBtn.disabled = false;
                stopBtn.disabled = true;
                updateStatus('å½•éŸ³å·²åœæ­¢', 'info');
                updateVadStatus('å·²åœæ­¢', false);
                
            } catch (error) {
                console.error('åœæ­¢å½•éŸ³å¤±è´¥:', error);
                updateStatus('åœæ­¢å½•éŸ³å¤±è´¥', 'error');
            }
        }
        
        // WebSocketè¿æ¥
        function connectWebSocket() {
            const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
            const wsUrl = `${protocol}//${window.location.host}/ws/interviewer`;
            ws = new WebSocket(wsUrl);

            ws.onopen = () => {
                updateStatus('æœåŠ¡å™¨è¿æ¥æˆåŠŸï¼Œæ­£åœ¨åˆå§‹åŒ–VAD...', 'success');
                // è¿æ¥æˆåŠŸååˆå§‹åŒ–VAD
                initializeVAD().then(success => {
                    if (success) {
                        startBtn.disabled = false;
                        updateStatus('ç³»ç»Ÿå‡†å¤‡å°±ç»ª', 'success');
                    }
                });
            };
            
            ws.onclose = () => {
                updateStatus('æœåŠ¡å™¨è¿æ¥æ–­å¼€ï¼Œæ­£åœ¨é‡è¿...', 'error');
                startBtn.disabled = true;
                stopBtn.disabled = true;
                setTimeout(connectWebSocket, 3000);
            };
            
            ws.onerror = (error) => {
                console.error('WebSocketé”™è¯¯:', error);
                updateStatus('è¿æ¥é”™è¯¯ï¼Œè¯·æ£€æŸ¥ç½‘ç»œ', 'error');
            };
            
            ws.onmessage = (event) => {
                try {
                    const data = JSON.parse(event.data);
                    handleServerMessage(data);
                } catch(e) { 
                    console.error("æ— æ³•è§£ææœåŠ¡å™¨æ¶ˆæ¯:", event.data); 
                }
            };
        }

        function handleServerMessage(data) {
            switch (data.type) {
                case 'recognition_result':
                    stats.recognized++;
                    updateStats();
                    updateStatus(`è¯†åˆ«: ${data.text}`, 'info');
                    break;
                case 'match_result':
                    stats.matched++;
                    updateStats();
                    updateStatus(`åŒ¹é…æˆåŠŸ: ${data.question}`, 'success');
                    break;
                case 'error':
                    updateStatus(`é”™è¯¯: ${data.message}`, 'error');
                    break;
            }
        }
        
        // äº‹ä»¶ç»‘å®š
        startBtn.onclick = startRecording;
        stopBtn.onclick = stopRecording;

        // é¡µé¢åŠ è½½æ—¶è¿æ¥WebSocket
        window.onload = () => {
            updateStatus('æ­£åœ¨è¿æ¥æœåŠ¡å™¨...', 'info');
            connectWebSocket();
        };

        // é¡µé¢å…³é—­æ—¶æ¸…ç†èµ„æº
        window.onbeforeunload = async () => {
            if (myvad && isRecording) {
                try {
                    await myvad.pause();
                } catch (e) {
                    console.log('æ¸…ç†VADæ—¶å‡ºé”™:', e);
                }
            }
            if (ws) ws.close();
        };
    </script>
</body>
</html>
    """
    return HTMLResponse(content=html_content)



@app.websocket("/ws/interviewee")
async def interviewee_websocket_endpoint(websocket: WebSocket):
    """é¢è¯•è€…å®¢æˆ·ç«¯è¿æ¥ç‚¹"""
    global interviewee_ws
    await websocket.accept()
    interviewee_ws = websocket
    print("âœ“ é¢è¯•è€…å®¢æˆ·ç«¯å·²è¿æ¥")
    
    try:
        while True:
            # ä¿æŒè¿æ¥ï¼Œå¯ä»¥æ¥æ”¶å¿ƒè·³æˆ–å‘½ä»¤
            data = await websocket.receive_text()
            if data == "ping":
                await websocket.send_text("pong")
    except WebSocketDisconnect:
        interviewee_ws = None
        print("âœ— é¢è¯•è€…å®¢æˆ·ç«¯å·²æ–­å¼€")

@app.websocket("/ws/interviewer")
async def interviewer_websocket_endpoint(websocket: WebSocket):
    """é¢è¯•å®˜æ‰‹æœºè¿æ¥ç‚¹"""
    await websocket.accept()
    print("âœ“ é¢è¯•å®˜æ‰‹æœºç«¯å·²è¿æ¥")
    
    try:
        while True:
            # æ¥æ”¶éŸ³é¢‘æ•°æ®
            audio_data = await websocket.receive_bytes()
            print(f"æ”¶åˆ°éŸ³é¢‘æ•°æ®ï¼Œå¤§å°: {len(audio_data)} å­—èŠ‚")
            
            # åœ¨å¤„ç†å‰å…ˆè¿›è¡Œæ ¼å¼è½¬æ¢
            wav_audio_data = convert_audio_to_wav(audio_data)
            
            if wav_audio_data:
                # ä½¿ç”¨è½¬æ¢åçš„æ•°æ®è¿›è¡Œå¤„ç†
                await process_audio(websocket, wav_audio_data)
            else:
                print("âœ— éŸ³é¢‘è½¬æ¢å¤±è´¥ï¼Œè·³è¿‡å¤„ç†")
            
    except WebSocketDisconnect:
        print("âœ— é¢è¯•å®˜æ‰‹æœºç«¯å·²æ–­å¼€")
    except Exception as e:
        print(f"å¤„ç†éŸ³é¢‘æ—¶å‡ºé”™: {e}")

async def process_audio(websocket: WebSocket, audio_data: bytes):
    """ä½¿ç”¨Voskå¤„ç†éŸ³é¢‘è¯†åˆ«å’ŒåŒ¹é…"""
    # æ£€æŸ¥Voskæ¨¡å‹æ˜¯å¦å·²åŠ è½½
    if not vosk_model:
        print("âœ— Voskæ¨¡å‹æœªåŠ è½½ï¼Œæ— æ³•è¿›è¡Œè¯†åˆ«")
        await websocket.send_text(json.dumps({
            'type': 'error', 
            'message': 'Voskè¯­éŸ³è¯†åˆ«æ¨¡å‹æœªåŠ è½½'
        }))
        return

    try:
        #å¼‚æ­¥å®ç°FFmpegè½¬æ¢
        wav_audio_data=await asyncio.to_thread(convert_audio_to_wav,audio_data)
        if not wav_audio_data:
            print("âœ— éŸ³è§†é¢‘è½¬æ¢å¤±è´¥ï¼Œè·³è¿‡å¤„ç†")
            return

        # å°†åŒæ­¥çš„Voskä»£ç å°è£…åœ¨ä¸€ä¸ªå‡½æ•°å†…
        def run_recognition(data):
            rec = KaldiRecognizer(vosk_model, 16000)
            rec.AcceptWaveform(data)
            return json.loads(rec.FinalResult())

        result = await asyncio.to_thread(run_recognition, wav_audio_data)
        text = result.get('text', '').replace(' ', '') # è·å–æ–‡æœ¬å¹¶ç§»é™¤ç©ºæ ¼
        
        if text:
            print(f"âœ“ ç¦»çº¿è¯†åˆ«ç»“æœ: {text}")
            
            # å‘é€è¯†åˆ«ç»“æœç»™é¢è¯•å®˜
            await websocket.send_text(json.dumps({
                'type': 'recognition_result',
                'text': text
            }))

            # åŒ¹é…ç­”æ¡ˆ (è¿™éƒ¨åˆ†é€»è¾‘ä¸å˜)
            if matcher and processor :
                
                #æç‚¼å…³é”®è¯
                cleaned_text = processor.clean_and_rebuild(text)
                if cleaned_text:

                    #å¼‚æ­¥è¿è¡Œè¯­ä¹‰åŒ¹é…
                    match_result = await asyncio.to_thread(matcher.match, cleaned_text)

                    if match_result:
                        answer = match_result['answer']
                        question = match_result['question']
                        similarity = match_result['similarity']
                        
                        print(f"âœ“ æ‰¾åˆ°åŒ¹é…ç­”æ¡ˆï¼Œç›¸ä¼¼åº¦: {similarity:.3f}")
                        
                        await websocket.send_text(json.dumps({
                            'type': 'match_result', 'question': question, 'similarity': similarity
                        }))
                        
                        if interviewee_ws:
                            formatted_answer = f"é—®é¢˜: {question}\n\nç­”æ¡ˆ: {answer}\n\n(ç›¸ä¼¼åº¦: {similarity:.2f})"
                            await interviewee_ws.send_text(formatted_answer)
                            print(f"âœ“ å·²å‘é€ç­”æ¡ˆç»™é¢è¯•è€…: {answer[:30]}...")
                    else:
                        print("âœ— æœªæ‰¾åˆ°åŒ¹é…çš„ç­”æ¡ˆ")
                        if interviewee_ws:
                            await interviewee_ws.send_text(f"æœªæ‰¾åˆ°åŒ¹é…ç­”æ¡ˆ: {text}")
            else:
                print("âœ— é—®é¢˜åŒ¹é…å™¨æœªåˆå§‹åŒ–")

        else:
            print("âœ— ç¦»çº¿è¯†åˆ«æœªèƒ½è§£æå‡ºæ–‡æœ¬")
            await websocket.send_text(json.dumps({
                'type': 'error', 'message': 'æ— æ³•ç†è§£éŸ³é¢‘å†…å®¹'
            }))

    except Exception as e:
        print(f"âœ— ç¦»çº¿è¯†åˆ«å¤„ç†æ—¶å‡ºé”™: {e}")
        await websocket.send_text(json.dumps({
            'type': 'error', 'message': f'å¤„ç†éŸ³é¢‘æ—¶å‡ºé”™: {e}'
        }))

@app.get("/status")
async def get_status():
    """è·å–æœåŠ¡çŠ¶æ€"""
    return {
        'status': 'running',
        'vosk_model_loaded': vosk_model is not None,
        'matcher_loaded': matcher is not None,
        'interviewee_connected': interviewee_ws is not None,
        'knowledge_base_stats': matcher.get_stats() if matcher else None
    }

if __name__ == "__main__":
    print("å¯åŠ¨é¢è¯•è¾…åŠ©å·¥å…·åç«¯æœåŠ¡...")
    uvicorn.run(app, host="0.0.0.0", port=8000)